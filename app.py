import streamlit as st
import tensorflow as tf
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
import numpy as np
import plotly.graph_objects as go
import cv2
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Flatten
from tensorflow.keras.optimizers import Adamax
from tensorflow.keras.metrics import Precision, Recall
import google.generativeai as genai
from google.colab import userdata
import PIL.Image
import os
from dotenv import load_dotenv
load_dotenv()

genai.configure(api_key = userdata.get("GOOGLE_API_KEY"))

output_dir = 'saliency_maps'
os.makedirs(output_dir , exist_ok=True)


output_dir = 'saliency_maps'
os.makedirs(output_dir , exist_ok=True)

def generate_explanation(img_path , model_prediction, confidence):

  prompt = f"""You are an expert neurologist. You are tasked with explaining a saliency map of a brain tumor MRI scan.
    The saliency map was generated by a deep learning model that was trained to classify brain tumors as either glioma, meningioma, pituitary, or no tumor.
    The deep learning model predicted the image to be of class '{model_prediction}' with a confidence of {confidence * 100}%.

    In your response:
    - Start with "This MRI Scan shows that these person is diagnosed from {model_prediction} due to ...." explain in scientific terms and what it e
    - Explain what regions of the brain the model is focusing on so that you know what it focused on to predict these
      Refer to the regions highlighted in light cyan, those are the regions where the model is focusing on.
    - Explain possible reasons why the model made the prediction it did
    - DO NOT mention "This model focusess on ..." or anything about the model
    - Talk like a neuro scientist using scientific terms
    - Keep your explanations to 5 sentence maximum

    Let's think step by step about this. Verify step by step.

  """

  img = PIL.Image.open(img_path)

  model = genai.GenerativeModel(model_name="gemini-1.5-flash")
  response = model.generate_content([prompt, img])

  return response.text


def generate_saliency_map(model, img_array, class_index, img_size, uploaded_file):
    # Generate gradients using GradientTape
    with tf.GradientTape() as tape:
        img_tensor = tf.convert_to_tensor(img_array, dtype=tf.float32)
        tape.watch(img_tensor)
        predictions = model(img_tensor)
        target_class = predictions[:, class_index]

    gradients = tape.gradient(target_class, img_tensor)

    # Apply Guided Backpropagation (ReLU on gradients for cleaner visualization)
    gradients = tf.maximum(gradients, 0)

    # Calculate saliency by taking the maximum across color channels
    gradients = tf.reduce_max(tf.abs(gradients), axis=-1)
    gradients = gradients.numpy().squeeze()

    # Resize gradients to match original image size
    gradients = cv2.resize(gradients, img_size)

    # Create a circular mask for the brain area
    center = (gradients.shape[0] // 2, gradients.shape[1] // 2)
    radius = min(center[0], center[1]) - 10
    y, x = np.ogrid[:gradients.shape[0], :gradients.shape[1]]
    mask = (x - center[0])**2 + (y - center[1])**2 <= radius**2

    # Apply mask to gradients
    gradients = gradients * mask

    # Normalize only the brain area
    brain_gradients = gradients[mask]
    if brain_gradients.max() > brain_gradients.min():
        brain_gradients = (brain_gradients - brain_gradients.min()) / (brain_gradients.max() - brain_gradients.min())
    gradients[mask] = brain_gradients

    # Apply a higher threshold to focus on most important regions
    threshold = np.percentile(gradients[mask], 75)  # Changed from 80 to 75 for more visible regions
    gradients[gradients < threshold] = 0

    # Apply smoothing
    gradients = cv2.GaussianBlur(gradients, (11, 11), 0)

    # Create a heatmap overlay with improved coloring
    # Using a better colormap approach
    import matplotlib.cm as cm

    # Normalize for colormap
    if gradients.max() > 0:
        gradients_norm = gradients / gradients.max()
    else:
        gradients_norm = gradients

    # Apply 'hot' colormap which is better for medical imaging
    cmap = cm.get_cmap('hot')
    heatmap = cmap(gradients_norm)
    heatmap = (heatmap[:, :, :3] * 255).astype(np.uint8)  # Remove alpha channel and convert to uint8

    # Resize heatmap to match original image size
    heatmap = cv2.resize(heatmap, img_size)

    # Load original image properly
    original_img = image.img_to_array(image.load_img(uploaded_file, target_size=img_size))
    original_img = original_img.astype(np.uint8)

    # Create better overlay - only overlay where there's significant activation
    alpha = 0.6  # heatmap opacity
    beta = 0.4   # original image opacity

    # Create mask for overlay (only where gradients are significant)
    overlay_mask = gradients_norm > 0.1

    superimposed_img = original_img.copy()
    for c in range(3):  # For each color channel
        superimposed_img[:, :, c] = np.where(
            overlay_mask,
            alpha * heatmap[:, :, c] + beta * original_img[:, :, c],
            original_img[:, :, c]
        )

    # Save the original uploaded file
    img_path = os.path.join(output_dir, uploaded_file.name)
    with open(img_path, "wb") as f:
        f.write(uploaded_file.getbuffer())

    saliency_map_path = f'saliency_maps/{uploaded_file.name}'

    # Save the saliency map
    cv2.imwrite(saliency_map_path, cv2.cvtColor(superimposed_img.astype(np.uint8), cv2.COLOR_RGB2BGR))

    return superimposed_img.astype(np.uint8)

def load_xception_model(model_path):
  img_shape = (299,299,3)

  base_model = tf.keras.applications.Xception(
      include_top = False,
      weights = 'imagenet',
      input_shape = img_shape,
      pooling = 'max'
  )

  model = Sequential([
      base_model,
      Flatten(),
      Dropout(rate = 0.3),
      Dense(128, activation = 'relu'),
      Dropout(rate = 0.25),
      Dense(4, activation = 'softmax')
  ])

  model.build((None,)+img_shape)

  model.compile(Adamax(learning_rate= 0.001),
              loss = 'categorical_crossentropy',
              metrics = [
                  'accuracy',
                  Precision(),
                  Recall()
              ])
  model.load_weights(model_path)

  return model


st.title('Brain Tumor Classification')
st.write('Upload an MRI scan to classify')

uploaded_file = st.file_uploader("Choose an Image....." , type=["jpg","jpeg","png"])

if uploaded_file is not None:
  selected_model = st.radio(
      "Select Model",
      ("Transfer Learning - Xception" , "Custom CNN")
  )
  if selected_model == "Transfer Learning - Xception":
    model = load_xception_model('/content/xception_model.weights.h5')
    img_size = (299,299)
  else:
    model = load_model('/content/cnn_model.h5')
    img_size = (224,224)

  labels = ['Glioma', 'Meningioma' , 'No Tumor' , 'Pituitary']
  img = image.load_img(uploaded_file, target_size = img_size)
  img_array = image.img_to_array(img)
  img_array = np.expand_dims(img_array , axis =0)
  img_array /= 255.0

  prediction = model.predict(img_array)

  class_index = np.argmax(prediction[0])
  result = labels[class_index]

  st.write(f'Predicted Class: {result}')
  st.write('Predictions: ')
  for label,prob in zip (labels,prediction[0]):
    st.write(f"{label}: {prob*100:.2f}%")

  saliency_map = generate_saliency_map(model , img_array, class_index, img_size, uploaded_file)

  col1,col2 = st.columns(2)
  with col1:
    st.image(uploaded_file,caption = "Uploaded Image" , use_container_width = True)
  with col2:
    st.image(saliency_map, caption = "Saliency Map" , use_container_width = True)

  st.write("## Classification Results")

  result_container = st.container()
  result_container.markdown(
     f"""
                  Prediction
                      {result}

                  Confidence
                      {prediction[0][class_index]:.4%}
      """,
      unsafe_allow_html=True
  )

  probabilities = prediction[0]
  sorted_indices = np.argsort(probabilities)[::-1]
  sorted_labels = [labels[i] for i in sorted_indices]
  sorted_probabilities = probabilities[sorted_indices]

  fig = go.Figure(go.Bar(
      x=sorted_probabilities,
      y=sorted_labels,
      orientation='h',
      marker_color=['red' if label == result else 'blue' for label in sorted_labels]
  ))

  fig.update_layout(
    title='Probabilities for each class',
    xaxis_title='Probability',
    yaxis_title='Class',
    height=400,
    width=600,
    yaxis=dict (autorange="reversed"))

  for i, prob in enumerate(sorted_probabilities):
    fig.add_annotation(
      x=prob,
      y=i,
      text=f'{prob:.4f}',
      showarrow=False,
      xanchor='left',
      xshift=5)

  st.plotly_chart(fig)

  saliency_map_path = f'saliency_maps/{uploaded_file.name}'
  explanation = generate_explanation(saliency_map_path, result, prediction[0][class_index])

  st.write("## Explanation")
  st.write(explanation)
     
